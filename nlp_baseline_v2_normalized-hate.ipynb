{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68696f7d-99f7-4a1b-97b1-882d0c5565e9",
   "metadata": {},
   "source": [
    "# [모의 캐글 - 게임] 비매너 댓글 식별 \n",
    "\n",
    "- 자연어 multi label classification 과제\n",
    "- 작성자 : MNC Sukyung Kim (skkim@mnc.ai)\n",
    "\n",
    "참고 논문 : \n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa42a1-848b-4d3b-b13e-b65cf0972404",
   "metadata": {},
   "source": [
    "# 1. 환경 설정 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c0e90b-6f4c-45fd-b83c-140dcde11d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ff15bef2-c669-4cb1-bf76-256154c4858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import *\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "from transformers import logging, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from transformers import ( \n",
    "    BertConfig,\n",
    "    ElectraConfig\n",
    ")\n",
    "\n",
    "### v2 에서 라이브러리 추가됨\n",
    "# 실험에 사용하실 모델 라이브러리를 추가하시는 걸 잊지 마세요!\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,  \n",
    "    AutoTokenizer,\n",
    "    ElectraTokenizer,\n",
    "    AlbertTokenizer,\n",
    "    \n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    AutoModel, \n",
    "    ElectraForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    AlbertForSequenceClassification,\n",
    "    AutoModelForSequenceClassification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c95b317-b37f-4c59-8eaf-25ce048eb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs:  1\n",
      "Does GPU exist? :  True\n"
     ]
    }
   ],
   "source": [
    "# 사용할 GPU 지정\n",
    "print(\"number of GPUs: \", torch.cuda.device_count())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Does GPU exist? : \", use_cuda)\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ffbcad1-d170-462f-807d-41760e65f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True 일 때 코드를 실행하면 example 등을 보여줌\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7484847-924d-4f99-8b41-190ae4f192e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file loaded.\n",
      "monologg/koelectra-base-v3-hate-speech\n"
     ]
    }
   ],
   "source": [
    "# config 파일 불러오기\n",
    "config_path = os.path.join('config_electra_v3_normalized.json')\n",
    "\n",
    "def set_config(config_path):\n",
    "    if os.path.lexists(config_path):\n",
    "        with open(config_path) as f:\n",
    "            args = AttrDict(json.load(f))\n",
    "            print(\"config file loaded.\")\n",
    "            print(args.pretrained_model)\n",
    "    else:\n",
    "        assert False, 'config json file cannot be found.. please check the path again.'\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "# 코드 중간중간에 끼워넣어 리셋 가능\n",
    "args = set_config(config_path)\n",
    "\n",
    "# 결과 저장 폴더 미리 생성\n",
    "# os.makedirs(args.result_dir, exist_ok=True)\n",
    "# os.makedirs(args.config_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04c99c-208b-46a1-82cd-a7c9c776c8ad",
   "metadata": {},
   "source": [
    "# 2. EDA 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ce6b8-7cb8-4b0e-bfb0-1b5f57437447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "04d14e2b-b2df-458c-8e3c-861ae5912646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "# data 경로 설정  \n",
    "train_path = os.path.join(args.data_dir,'train_normalized2.csv')\n",
    "\n",
    "print(\"train 데이터 경로가 올바른가요? : \", os.path.lexists(train_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3123598-d707-467a-a380-99644a9a3637",
   "metadata": {},
   "source": [
    "### 2-1. Train 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3d5cb19-0e61-4358-9a9b-c690cbe8c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0         미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1         극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2             손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                  섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4  임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "\n",
       "                                             comment    bias  hate  \n",
       "0                                    김태리 정말 연기 잘해 진짜    none  none  \n",
       "1                    공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까    none  hate  \n",
       "2  누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate  \n",
       "3                                           일본 축구 져라    none  none  \n",
       "4                           난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path,encoding = 'UTF-8-SIG') # encoding = 'UTF-8-SIG' 원본\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "caec30f6-1fe1-40b2-81ba-7015a0266f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62323927-527d-4259-8a0f-47d4130e5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([2650,3780,6310],inplace=True)\n",
    "train_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "466dc16e-e3d7-4d38-904a-679810657742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길</td>\n",
       "      <td>아니 근데 튜닝 한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>그들만의 세상홍상수김민희 새해데이트에 반응싸늘</td>\n",
       "      <td>참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>시크릿 마더 김소연 누가 죽였나송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>허지웅소속사 악성림프종 진단 치료 전념</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8364 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0            미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1            극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2                손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                     섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4     임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "...                                          ...   \n",
       "8359              배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길   \n",
       "8360               마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상   \n",
       "8361                   그들만의 세상홍상수김민희 새해데이트에 반응싸늘   \n",
       "8362                    시크릿 마더 김소연 누가 죽였나송윤아와 갈등   \n",
       "8363                       허지웅소속사 악성림프종 진단 치료 전념   \n",
       "\n",
       "                                                comment    bias  hate  \n",
       "0                                       김태리 정말 연기 잘해 진짜    none  none  \n",
       "1                       공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까    none  hate  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate  \n",
       "3                                              일본 축구 져라    none  none  \n",
       "4                              난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none  \n",
       "...                                                 ...     ...   ...  \n",
       "8359  아니 근데 튜닝 한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서...  others  hate  \n",
       "8360  그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...  gender  hate  \n",
       "8361       참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다    none  none  \n",
       "8362                                            재미가 없어요    none  none  \n",
       "8363                                              쭉 쉬세요    none  hate  \n",
       "\n",
       "[8364 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce65d19-028f-4dc6-96e2-a9ac0949b5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### v2 에서 추가됨\n",
    "\n",
    "# title 중 가장 긴 타이틀 길이\n",
    "max_len_title = np.max(train_df['title'].str.len())\n",
    "max_len_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b449c22-6103-4cb9-9900-a2c3f7a7a109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comment 중 가장 긴 타이틀 길이\n",
    "max_len_comment=np.max(train_df['comment'].str.len())\n",
    "max_len_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f674ee-0184-4635-b353-d9975649fb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136     진짜 연기 못하는 애들만 모아뒀네 월화 드라마가 시청률 똥 마이라 드라마 잠정 폐지...\n",
       "170     개 쳐늙으면 꼴 보기 싫어지는 게 사람의 마음이 지 얘네야 광고 수익으로 번 게 많...\n",
       "256     남자 지갑 꺼내 어쩌 내 말 많은데 쟤 갤러리아 포레사는 데 한국에서 10위권 안에...\n",
       "424     쿵쾅이 들아 너네가 알아야 할 게 눈코 입 윤곽 다 해도 겨우 중 타치든가 다 해도...\n",
       "657     수아가 불쌍하다 납치돼서 20년을 힘들게 살고 남자 놈은 수아 버리고 민 채린한테 ...\n",
       "1236    예능에서 자주 나오는 웃기려고 하는 거지만 상당히 정확한 전기 오는 거짓말탐지기 유...\n",
       "1296    어쩐지 1위부터 와 꾸가 빻 고 나머지들 와 꾸가 개 빻았길래 이 게 아이돌이야 싶...\n",
       "1335    송민호 혼자 왜 설거지 시켰어요 골병들겠다 피오가 많이 도와줘야 할 텐데 송민호 키...\n",
       "1437    그냥 좀 착하게 살면 안 되겠냐 여기다가 설정이 네 어쩌 네 썰 전 펼치면서 애 하...\n",
       "1609    역시 힙합은 마약과 떨어질 수 없는 자르지 그만큼 한국 오버 힙합은 YG가 책임지고...\n",
       "1643    세 가족 모두 짠했지만 반듯하게 잘 크고 있는 건 아빠의 빈자리를 엄마의 역할이 배...\n",
       "1929    두 분 가정살이에 왜 남들이 이래저래 하는지 그런 면 두 분이 일반이면 저렇게까지 ...\n",
       "2066    솔직히 남자들 사이에서 저런 거 올리면 욕하기도 그렇고 좀 가만있게 될 거 같다 로...\n",
       "2567    솔직히 한 혜진 이제 나이가 37살 되는데 사실 일반인 여자이면 결혼 이미 포기하는...\n",
       "2654    내가 너를 고소하고 싶어 정국 아 진짜 존 나 패고 싶다 생각이 없니 국뽕으로 뭘 ...\n",
       "2701    사장들 긴장해서 인터뷰 장소에서 지적당하는 화면 보며 더 우울해하는데 옆에 조보아 ...\n",
       "3067    솔까 마다 욕하는 인간들 치고 돈 안 떼인 인간 없지 싶다 안 그러고는 불구대천 원...\n",
       "3264    댓글들에 역겨운 애들 많네 자기들 집 앞이었으면 게거품 물고 쓰러질 것들이 ㅋㅋ 그...\n",
       "3385    우하 하 키 ㅣ득 어쩌면 좋아 일본에서 활동할 팀은 이제부터 느 ㄴ 아이지원이 당 ...\n",
       "3571    무안주 고 개 쪽 준 건지면서 무슨 상처 물론 고장환이 잘못한 건 맞지만 딱 상상이...\n",
       "3626    고현정 배 되지가 불러서 그런 행동하는 거지 돈이 아쉬워서 하는 것도 아니니 제 맘...\n",
       "3753    신태용 임기응변 보소 나는 유종의 미만 거두면 되겠다 ㅋㅋ 그 결과가 네가 잘한 거...\n",
       "3911    모델 앞에 선 찍 소리도 못할 안경 여드름 돼지 쿵쾅 우들이 건 수 하나 잡았다고 ...\n",
       "4041    작품 준비하면서 호르몬제나 얼굴형 관리 엄청 받았을 거에 요 그렇지 않고서는 안 그...\n",
       "4164    나이 차이 외모 이런 거로 뭐라 하지 마라 좀 ㅡ여자인 함 소원이도 18살 어린 남...\n",
       "4278    저기 요 유병재는 머 하는 사람임 억지웃음에 다 재미도 하나 없건만 저 프로에는 누...\n",
       "4288    아들 결혼식에서 옥자 씨 잘해줄 게는 웬 말 ㅠㅠ이 아저씨 정말 진상이야 짜증 나 ...\n",
       "4773    OOO들 모임이 네 뉴스에 1분도 못 나오는 뒷방 3류 아나라 잃을 것도 없이 친문...\n",
       "4972    분별없는 피해자가 가해자를 죽음으로 내몰 다니 좌파 정권이 득실 데는 장에서 한 사...\n",
       "4984    안재현 소속사 돈 많이 들겠네 요 구혜선인 스타만 하면 기사 네이버 상위에 올려야지...\n",
       "5083    조선일보 기자 야 검은 머리 외국인을 이런데 써먹지 마라 드라마 재밌게 보다 가 기...\n",
       "5158    이 늙은 거는 나중에 이 혼의 자료 많이 받으려고 하는 거 딱 보이는데 ㅎㅎ 남편이...\n",
       "5405    어디 가 폭발적인 화제를 몰고 다녔는데 나만 몰랐나 봄 기자들은 제발 연예인들이 자...\n",
       "5539    김태호 도 감이 떨어진 게 유재석은 패널들에 얹혀가는 자가발전 안 되는 십 거품인데...\n",
       "5579    악플 쓰는 아가들아 너희들도 똑같은 범죄자 다 꼴 보기 싫으면 제발 관심 말고 무관...\n",
       "5624    레깅스 완판해서 아디다스 정식 모델 됐고 다른 제품도 완판 많이 해서 개인 광고 8...\n",
       "5869    얘 전에 후원자랑 뭔 일 터졌던 거 같은데 벌써 결혼이야 ㅋㅋ 그 일 있고 나서 완...\n",
       "5977    안재현 망할 놈 얼마나 개망 나니 같이 행동했으면 구 혜선이 하나를 품을까 구혜선 ...\n",
       "6068    네놈이 실력이 있냐 외모가 출 중하냐 호감형이 길하냐 키라도 크냐 천운으로 이름 좀...\n",
       "6150    왜 대학 cc를 하면 안 되는지 연예인들이 보여주 네 ㅋ 남자는 개인적인 일에 대해...\n",
       "6466    근데 왜 팩트가 지금 조사 중이고 아직 확정 아니고 확정해봐야 성폭행했으면 셰프가 ...\n",
       "6498    자막 똑바로 쓰지 하나도 안 귀엽고 그런 발음 아닌데 일부러 쓰고 해 써라고 하는데...\n",
       "6544    이거 손혜원 등 좌파 사건 덮으려고 현 정부가 묵 혀 두고 있던 거 이제 터트린 거...\n",
       "6728    문식 다연 재형 이 세 명 때문에 봄 물론 경수랑 선하랑 다시 만나는데 결혼 생각 ...\n",
       "6916    또 전라도 홍어들 특유의 피해자 코스레냐 티아라 쌍둥이 홍어들도 알고 보니 홍어들이...\n",
       "7002    이 분은 인스타 올리지도 못하나 열등감도 정도껏 해야지 ㅉㅉ 여기 악플 다는 사람들...\n",
       "8130    방송 출연해서 이런 말 막 해도 되나 김학래는 가 정 없이 혼자 사는 분인가 그리고...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 길이가 128이 넘는 코멘트 확인\n",
    "train_df['comment'][train_df['comment'].str.len()>128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10dee23-db6d-4fce-8b06-054c3457adaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8364"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bb12cc-25bb-4842-9720-c61679573984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길</td>\n",
       "      <td>아니 근데 튜닝한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>그들만의 세상홍상수김민희 새해데이트에 반응싸늘</td>\n",
       "      <td>참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>시크릿 마더 김소연 누가 죽였나송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>허지웅소속사 악성림프종 진단 치료 전념</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8364 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0            미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1            극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2                손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                     섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4     임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "...                                          ...   \n",
       "8359              배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길   \n",
       "8360               마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상   \n",
       "8361                   그들만의 세상홍상수김민희 새해데이트에 반응싸늘   \n",
       "8362                    시크릿 마더 김소연 누가 죽였나송윤아와 갈등   \n",
       "8363                       허지웅소속사 악성림프종 진단 치료 전념   \n",
       "\n",
       "                                                comment    bias  hate  \n",
       "0                                       김태리 정말 연기 잘해 진짜    none  none  \n",
       "1                        공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까    none  hate  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate  \n",
       "3                                              일본 축구 져라    none  none  \n",
       "4                              난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none  \n",
       "...                                                 ...     ...   ...  \n",
       "8359  아니 근데 튜닝한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서 ...  others  hate  \n",
       "8360  그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...  gender  hate  \n",
       "8361       참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다    none  none  \n",
       "8362                                            재미가 없어요    none  none  \n",
       "8363                                              쭉 쉬세요    none  hate  \n",
       "\n",
       "[8364 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ecb32ed-e7f9-4640-89c2-87005a9aed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias classes:  ['none' 'others' 'gender']\n",
      "hate classes:  ['none' 'hate']\n"
     ]
    }
   ],
   "source": [
    "# print(\"bias classes: \", train_df.bias.unique())\n",
    "# print(\"hate classes: \", train_df.hate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faecbd1a-82ee-40ed-b81a-2984674b669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>hate</th>\n",
       "      <th>hate</th>\n",
       "      <th>none</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1216</td>\n",
       "      <td>83</td>\n",
       "      <td>1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>2065</td>\n",
       "      <td>3422</td>\n",
       "      <td>5487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>1437</td>\n",
       "      <td>141</td>\n",
       "      <td>1578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4718</td>\n",
       "      <td>3646</td>\n",
       "      <td>8364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "hate    hate  none   All\n",
       "bias                    \n",
       "gender  1216    83  1299\n",
       "none    2065  3422  5487\n",
       "others  1437   141  1578\n",
       "All     4718  3646  8364"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.crosstab(train_df.bias, train_df.hate, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3802b-a501-4adc-9f9a-6968df7684d3",
   "metadata": {},
   "source": [
    "### 2-2. Test 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86211318-bfaa-47c7-9653-63a13905dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(args.data_dir,'test_normalized2.csv')\n",
    "print(\"test 데이터 경로가 올바른가요? : \", os.path.lexists(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a713f829-09c9-468a-8266-4bd555e29906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>류현경박성훈 공개연애 4년차 애정전선 이상無의지 많이 된다</td>\n",
       "      <td>둘 다 너무 좋다 행복하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>현금 유도1인 1라면골목식당 백종원 초심 잃은 도시락집에 경악</td>\n",
       "      <td>근데 만 원 이하는 현금 결제만 하라고 써놓은 집 우리나라에 엄청 많은데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>입대 D11 서은광의 슬픈 멜로디비투비 눈물의 첫 체조경기장</td>\n",
       "      <td>누군데 얘네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>아이콘택트 리쌍 길 3년 전 결혼설 부인한 이유 공개결혼출산 숨겼다</td>\n",
       "      <td>쇼하지 마라 자식 아 음주 1번은 실수 2번은 고의 3번은 인간쓰레기 다 슬 금슬은...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>구하라 안검하수 반박 해프닝당당하다vs그렇게까지 설전</td>\n",
       "      <td>안검하수 가지고 있는 분께 희망을 주고 싶은 건가요 수술하면 이렇게 자연스러워진다고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID                                  title  \\\n",
       "0  0       류현경박성훈 공개연애 4년차 애정전선 이상無의지 많이 된다   \n",
       "1  1     현금 유도1인 1라면골목식당 백종원 초심 잃은 도시락집에 경악   \n",
       "2  2      입대 D11 서은광의 슬픈 멜로디비투비 눈물의 첫 체조경기장   \n",
       "3  3  아이콘택트 리쌍 길 3년 전 결혼설 부인한 이유 공개결혼출산 숨겼다   \n",
       "4  4          구하라 안검하수 반박 해프닝당당하다vs그렇게까지 설전   \n",
       "\n",
       "                                             comment  \n",
       "0                                    둘 다 너무 좋다 행복하세요  \n",
       "1           근데 만 원 이하는 현금 결제만 하라고 써놓은 집 우리나라에 엄청 많은데  \n",
       "2                                             누군데 얘네  \n",
       "3  쇼하지 마라 자식 아 음주 1번은 실수 2번은 고의 3번은 인간쓰레기 다 슬 금슬은...  \n",
       "4  안검하수 가지고 있는 분께 희망을 주고 싶은 건가요 수술하면 이렇게 자연스러워진다고...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_path)\n",
    "test_df = test_df.astype('str')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "6ad5fbb7-acb5-47cb-b0f3-b220bf78ab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb5aa8-6284-4066-a69d-a1539c5287a5",
   "metadata": {},
   "source": [
    "### 2-3. 데이터 전처리 (Label Encoding)\n",
    "bias, hate 라벨들의 class를 정수로 변경하여 라벨 인코딩을 하기 위한 딕셔너리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11018420-84da-40ac-b892-4e47f20dd83f",
   "metadata": {},
   "source": [
    "- bias, hate 컬럼을 합쳐서 하나의 라벨로 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38c61bc4-da4a-4fc3-9cff-62079051ed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['none' 'none']\n",
      " ['none' 'hate']\n",
      " ['others' 'none']\n",
      " ['others' 'hate']\n",
      " ['gender' 'none']\n",
      " ['gender' 'hate']]\n"
     ]
    }
   ],
   "source": [
    "# 두 라벨의 가능한 모든 조합 만들기\n",
    "# combinations = np.array(np.meshgrid(train_df.bias.unique(), train_df.hate.unique())).T.reshape(-1,2)\n",
    "\n",
    "# if DEBUG==True:\n",
    "#     print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c1f00cb-8009-460f-8903-ca876d647ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['none', 'none'], dtype=object), array(['none', 'hate'], dtype=object), array(['others', 'hate'], dtype=object), array(['none', 'none'], dtype=object), array(['none', 'none'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# bias, hate 컬럼을 합친 것\n",
    "# bias_hate = list(np.array([train_df['bias'].values, train_df['hate'].values]).T.reshape(-1,2))\n",
    "\n",
    "# if DEBUG==True:\n",
    "#     print(bias_hate[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26376de0-2a54-44c2-a8af-f20025b9798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0         미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1         극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2             손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                  섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4  임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "\n",
       "                                             comment    bias  hate  label  \n",
       "0                                    김태리 정말 연기 잘해 진짜    none  none      0  \n",
       "1                     공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까    none  hate      1  \n",
       "2  누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...  others  hate      3  \n",
       "3                                           일본 축구 져라    none  none      0  \n",
       "4                           난 절대로 임현주 욕하는 인간이랑은 안 논다    none  none      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = []\n",
    "# for i, arr in enumerate(bias_hate):\n",
    "#     for idx, elem in enumerate(combinations):\n",
    "#         if np.array_equal(elem, arr):\n",
    "#             labels.append(idx)\n",
    "\n",
    "# train_df['label'] = labels\n",
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adf07d93-3a68-4c36-837f-839331400db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title  \\\n",
       "0         미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1         극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2             손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                  섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4  임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "\n",
       "                                             comment  bias  hate  \n",
       "0                                    김태리 정말 연기 잘해 진짜     0     0  \n",
       "1                    공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까     0     1  \n",
       "2  누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...     2     1  \n",
       "3                                           일본 축구 져라     0     0  \n",
       "4                           난 절대로 임현주 욕하는 인간이랑은 안 논다     0     0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hate speech 모델도 아웃풋이 3개로 나오는 모델이라 따로 라벨을 만들어줌 원래 offensive 항목이 있었으나 이자료에서는 hate로 통합했기때문에 그냥 씀\n",
    "train_df['bias'].replace({\"none\":0, \"gender\":1, \"others\":2}, inplace=True)\n",
    "train_df['hate'].replace({\"none\":0, \"hate\":1}, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8360124a-e3cd-4cb6-9549-e2e06c1f2db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8364 entries, 0 to 8363\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    8364 non-null   object\n",
      " 1   comment  8364 non-null   object\n",
      " 2   bias     8364 non-null   int64 \n",
      " 3   hate     8364 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 261.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add80824-55c5-4ca3-9858-5aeee3ede98d",
   "metadata": {},
   "source": [
    "## 3. Dataset 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9956c57-af6a-4330-a531-a338be9da9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3-0. Pre-trained tokenizer 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bd6f75f4-cdf7-4998-8b78-3aa716b7045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.json 에서 지정 이름별로 가져올 라이브러리 지정\n",
    "\n",
    "TOKENIZER_CLASSES = {\n",
    "    \"BertTokenizer\": BertTokenizer,\n",
    "    \"AutoTokenizer\": AutoTokenizer,\n",
    "    \"ElectraTokenizer\": ElectraTokenizer,\n",
    "    \"AlbertTokenizer\": AlbertTokenizer,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a285fec-0b39-4dce-8dc0-6faa6b027c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Tokenizer 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7d0f1e57-caf8-4d67-a2a9-61284a793f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizerFast(name_or_path='monologg/koelectra-base-v3-hate-speech', vocab_size=35000, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = TOKENIZER_CLASSES[args.tokenizer_class].from_pretrained(args.pretrained_model)\n",
    "if DEBUG==True:\n",
    "    print(TOKENIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a1786b-1a43-430f-829b-83fcca289b99",
   "metadata": {},
   "source": [
    "# [모의 캐글 - 게임] 비매너 댓글 식별 \n",
    "\n",
    "- 자연어 multi label classification 과제\n",
    "- 작성자 : MNC Sukyung Kim (skkim@mnc.ai)\n",
    "\n",
    "참고 논문 : \n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a54603f-3801-4231-9c66-81dfb1e87587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['title'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cde2ce51-b535-4208-abe8-0f5662aba97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'김태리 정말 연기 잘해 진짜'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['comment'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e8cdb8e-41a8-4d51-8aa0-f305782416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 9945, 4108, 6595, 7144, 3258, 4151, 7082, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "if DEBUG == True:\n",
    "    example = train_df['title'][0]\n",
    "    comment_ex = train_df['comment'][0]\n",
    "    print(TOKENIZER(comment_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f174365c-90da-4c32-b6b4-5d66525a0687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 11100, 2936, 4825, 4139, 2772, 4150, 4283, 9945, 4108, 4192, 2024, 4112, 18723, 3247, 4219, 31950, 6673, 6372, 4034, 3] \n",
      "\n",
      "['미스터', '션', '##샤', '##인', '변', '##요', '##한', '김태', '##리', '##와', '같', '##은', '양복', '입', '##고', '학당', '방문', '이유', '##는'] \n",
      "\n",
      "['김태', '##리', '정말', '연기', '잘', '##해', '진짜'] \n",
      "\n",
      "[11100, 2936, 4825, 4139, 2772, 4150, 4283, 9945, 4108, 4192, 2024, 4112, 18723, 3247, 4219, 31950, 6673, 6372, 4034]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG==True:\n",
    "    print(TOKENIZER.encode(example),\"\\n\")\n",
    "    \n",
    "    # 토큰으로 나누기\n",
    "    print(TOKENIZER.tokenize(example),\"\\n\")\n",
    "    \n",
    "    print(TOKENIZER.tokenize(comment_ex),\"\\n\")\n",
    "    \n",
    "    # 토큰 id로 매핑하기\n",
    "    print(TOKENIZER.convert_tokens_to_ids(TOKENIZER.tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1708e-aedb-402f-a9c3-20ebdbe537eb",
   "metadata": {},
   "source": [
    "### 3-1. Dataset 만드는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "471fc2cc-5e79-4883-9ae5-4803722732c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['bias'],axis=1,inplace=True) # bias 라벨을 떨궈줌 hate 라벨만 쓰기위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d577a4de-945d-4ca0-94be-67fb58034ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['title','comment','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f91f8e9-64b4-4c0a-95da-7dcdb3d24073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부</td>\n",
       "      <td>공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8359</th>\n",
       "      <td>배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길</td>\n",
       "      <td>아니 근데 튜닝 한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8360</th>\n",
       "      <td>마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>그들만의 세상홍상수김민희 새해데이트에 반응싸늘</td>\n",
       "      <td>참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>시크릿 마더 김소연 누가 죽였나송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>허지웅소속사 악성림프종 진단 치료 전념</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0            미스터 션샤인 변요한 김태리와 같은 양복 입고 학당 방문 이유는   \n",
       "1            극사실주의 현실가장 보통의 연애 김래원X공효진 16년만의 랑데부   \n",
       "2                손연재 리듬체조 학원 선생님 하고 싶은 일 해서 행복하다   \n",
       "3                     섹션TV 김해숙 허스토리 촬영 후 우울증 얻었다   \n",
       "4     임현주 아나운서 노브라 챌린지 방송 덕에 낸 용기 자연스런 논의의 창 됐으면   \n",
       "...                                          ...   \n",
       "8359              배우 이필립 SNS 스타 연인에게 초호화 프러포즈 눈길   \n",
       "8360               마약백스텝김새롬 탓 실형 피한 이찬오 이미지는 치명상   \n",
       "8361                   그들만의 세상홍상수김민희 새해데이트에 반응싸늘   \n",
       "8362                    시크릿 마더 김소연 누가 죽였나송윤아와 갈등   \n",
       "8363                       허지웅소속사 악성림프종 진단 치료 전념   \n",
       "\n",
       "                                                comment  label  \n",
       "0                                       김태리 정말 연기 잘해 진짜      0  \n",
       "1                       공효진 발 연기나 이 질 생각이 없던데 왜 계속 주연일까      1  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길 행복은 머니 순이 아니니깐 작은 ...      1  \n",
       "3                                              일본 축구 져라      0  \n",
       "4                              난 절대로 임현주 욕하는 인간이랑은 안 논다      0  \n",
       "...                                                 ...    ...  \n",
       "8359  아니 근데 튜닝 한 사람은 프러 포즈 받지도 결혼도 못함 ᄏᄏᄏ 자기들은 돈 없어서...      1  \n",
       "8360  그러니깐 여자를 잘 만나야 돼 징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯...      1  \n",
       "8361       참으로 아름다운 커플입니다 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다      0  \n",
       "8362                                            재미가 없어요      0  \n",
       "8363                                              쭉 쉬세요      1  \n",
       "\n",
       "[8364 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "85e6f065-671c-435c-8e73-8cad3c1496a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_len, mode = 'train'):\n",
    "\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            try: \n",
    "                self.labels = df['label'].tolist()\n",
    "            except:\n",
    "                assert False, 'CustomDataset Error : \\'label\\' column does not exist in the dataframe'\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "                \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        전체 데이터에서 특정 인덱스 (idx)에 해당하는 기사제목과 댓글 내용을 \n",
    "        토크나이즈한 data('input_ids', 'attention_mask','token_type_ids')의 딕셔너리 형태로 불러옴\n",
    "        \"\"\"\n",
    "        title = self.data.title.iloc[idx]\n",
    "        comment = self.data.comment.iloc[idx]\n",
    "        \n",
    "        tokenized_text = self.tokenizer(comment, #title 은 학습에 사용하지 않아 지웠음.\n",
    "                             padding= 'max_length',\n",
    "                             max_length=self.max_len,\n",
    "                             truncation=True,\n",
    "                             return_token_type_ids=True,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors = \"pt\")\n",
    "        \n",
    "        data = {'input_ids': tokenized_text['input_ids'].clone().detach().long(),\n",
    "               'attention_mask': tokenized_text['attention_mask'].clone().detach().long(),\n",
    "               'token_type_ids': tokenized_text['token_type_ids'].clone().detach().long(),\n",
    "               }\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            label = self.data.label.iloc[idx]\n",
    "            return data, label\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "\n",
    "    \n",
    "train_dataset = CustomDataset(train_df, TOKENIZER,args.max_seq_len , mode ='train')\n",
    "print(\"train dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7d27241c-4c3b-498e-9456-871dc3cc2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample : \n",
      "({'input_ids': tensor([[    2,  2085, 30497,  2735,  7144,  4065,  3240,  3351,  6243,  4007,\n",
      "          3123,  4820,  4244,  3178,  6437, 12242,  4366,  4149,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}, 1)\n"
     ]
    }
   ],
   "source": [
    "if DEBUG ==True :\n",
    "    print(\"dataset sample : \")\n",
    "    print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbadd376-0df2-455c-89f1-9236ba9d32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_plus = tokenizer.encode_plus(\n",
    "#                     sentence,                      # Sentence to encode.\n",
    "#                     add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#                     max_length = 128,           # Pad & truncate all sentences.\n",
    "#                     pad_to_max_length = True,\n",
    "#                     return_attention_mask = True,   # Construct attention masks.\n",
    "#                     return_tensors = 'pt',     # Return pytorch tensors.\n",
    "#                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d12dd-7a1e-423f-8b3d-00bae3c17375",
   "metadata": {},
   "source": [
    "### 3-2. Train, Validation set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6fb9525-861d-48ba-b495-828b8a08b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  7527\n",
      "Validation dataset:  837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=args.seed)\n",
    "\n",
    "train_dataset = CustomDataset(train_data, TOKENIZER, args.max_seq_len, 'train')\n",
    "val_dataset = CustomDataset(val_data, TOKENIZER, args.max_seq_len, 'validation')\n",
    "\n",
    "print(\"Train dataset: \", len(train_dataset))\n",
    "print(\"Validation dataset: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2dc89ce-dada-4fce-8181-6a4993cb377c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   2, 3308, 4113, 4007, 2010, 2245, 4050, 4140, 6683, 4007, 6327, 6231,\n",
       "        4176, 6226, 4112,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ef6671-515e-4af6-98e2-64371f40011e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset[0][0]['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed493727-edd8-43ba-924f-195837306952",
   "metadata": {},
   "source": [
    "## 4. 분류 모델 학습을 위한 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0817a-8b51-4d22-9f31-eb8bd22640cb",
   "metadata": {},
   "source": [
    "### 4-1. 아키텍쳐 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a250764-25aa-43e4-a383-f464dc54bc25",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- [PretrainedConfig](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)\n",
    "-[KcELECTRA 사전학습 모델](https://github.com/Beomi/KcELECTRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "554c0acd-d158-4d36-bfd1-abb47fb618f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import logging    \n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# config.json 에 입력된 architecture 에 따라 베이스 모델 설정\n",
    "BASE_MODELS = {\n",
    "    \"BertForSequenceClassification\": BertForSequenceClassification,\n",
    "    \"AutoModel\": AutoModel,\n",
    "    \"ElectraForSequenceClassification\": ElectraForSequenceClassification,\n",
    "    \"AlbertForSequenceClassification\": AlbertForSequenceClassification,\n",
    "    \"AutoModelForSequenceClassification\":AutoModelForSequenceClassification\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "myModel = BASE_MODELS[args.architecture].from_pretrained(args.pretrained_model, \n",
    "                                                         num_labels = args.num_classes, \n",
    "                                                         output_attentions = False, # Whether the model returns attentions weights.\n",
    "                                                         output_hidden_states = True # Whether the model returns all hidden-states.\n",
    "                                                        )\n",
    "if DEBUG==True:\n",
    "    # 모델 구조 확인\n",
    "    print(myModel)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5f90f3c-51f6-4b44-a426-a0b36ccfa852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022a093-130f-40ac-b8e5-8decc5c63a6d",
   "metadata": {},
   "source": [
    "### 4-2. 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d37b1b-d491-4d3c-8551-980f78a78337",
   "metadata": {},
   "source": [
    "\n",
    "- BertForSequenceClassifier (line 1232부터 참고) [source code](https://github.com/huggingface/transformers/blob/a39dfe4fb122c11be98a563fb8ca43b322e01036/src/transformers/modeling_bert.py#L1284-L1287)\n",
    "\n",
    "- ElectraForSequenceClassifier [source code](https://huggingface.co/transformers/v3.0.2/_modules/transformers/modeling_electra.html#ElectraForSequenceClassification)\n",
    "\n",
    "- SequenceClassier output 형태 : tuple(torch.FloatTensor)\n",
    "    - loss (torch.FloatTensor of shape (1,), optional, returned when label is provided):\n",
    "    Classification (or regression if config.num_labels==1) loss.\n",
    "\n",
    "   - logits (torch.FloatTensor of shape (batch_size, config.num_labels)):\n",
    "    Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "\n",
    "    - hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True):\n",
    "    Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "\n",
    "    - Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "\n",
    "    - attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True):\n",
    "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "\n",
    "    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
    "    \n",
    "    \n",
    "- v2 에서 수정 및 추가 된 부분 많음\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1685ce12-7238-4e2a-a20d-11969b568807",
   "metadata": {},
   "outputs": [],
   "source": [
    "### v2 에서 일부 수정됨\n",
    "class myClassifier(nn.Module):\n",
    "    def __init__(self, model, hidden_size = 768, num_classes=args.num_classes, selected_layers=False, params=None):\n",
    "        super(myClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        self.selected_layers = selected_layers\n",
    "        \n",
    "        # 사실 dr rate은 model config 에서 hidden_dropout_prob로 가져와야 하는데 bert에선 0.1이 쓰였음\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, segment_ids):      \n",
    "        outputs = self.model(input_ids = token_ids, \n",
    "                             token_type_ids = segment_ids.long(), \n",
    "                             attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        \n",
    "        # hidden state에서 마지막 4개 레이어를 뽑아 합쳐 새로운 pooled output 을 만드는 시도\n",
    "        if self.selected_layers == True:\n",
    "            hidden_states = outputs.hidden_states\n",
    "            pooled_output = torch.cat(tuple([hidden_states[i] for i in [-4, -3, -2, -1]]), dim=-1)\n",
    "            # print(\"concatenated output shape: \", pooled_output.shape)\n",
    "            ## dim(batch_size, max_seq_len, hidden_dim) 에서 가운데를 0이라 지정함으로, [cls] 토큰의 임베딩을 가져온다. \n",
    "            ## (text classification 구조 참고)\n",
    "            pooled_output = pooled_output[:, 0, :]\n",
    "            # print(pooled_output)\n",
    "\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "            ## 3개의 레이어를 합치므로 classifier의 차원은 (hidden_dim, 6)이다\n",
    "            classifier = nn.Linear(pooled_output.shape[1], args.num_classes).to(token_ids.device)\n",
    "            logits = classifier(pooled_output)\n",
    "        \n",
    "        else:\n",
    "            logits=outputs.logits\n",
    "        \n",
    "    \n",
    "        # 각 클래스별 확률\n",
    "        prob= self.softmax(logits)\n",
    "        # print(prob)\n",
    "        # logits2 = outputs.logits\n",
    "        # print(self.softmax(logits2))\n",
    "\n",
    "\n",
    "        return logits, prob\n",
    "        \n",
    "# 마지막 4 hidden layers concat 하는 방법을 쓰신다면 True로 변경        \n",
    "model = myClassifier(myModel, selected_layers=False)\n",
    "\n",
    "# if DEBUG ==True :\n",
    "#     print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf359650-bc3c-4a9d-b486-e25496932285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99386a8c-7795-454c-9a32-eaf447c6fc4c",
   "metadata": {},
   "source": [
    "### 4-3. 모델 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e3b6bc6f-1df3-46fb-a607-5de3e3cef571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "model.electra.embeddings.word_embeddings.weight         (35000, 768)\n",
      "model.electra.embeddings.position_embeddings.weight       (512, 768)\n",
      "model.electra.embeddings.token_type_embeddings.weight       (2, 768)\n",
      "model.electra.embeddings.LayerNorm.weight                     (768,)\n",
      "model.electra.embeddings.LayerNorm.bias                       (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "model.electra.encoder.layer.0.attention.self.query.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.query.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.self.key.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.key.bias         (768,)\n",
      "model.electra.encoder.layer.0.attention.self.value.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.value.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.dense.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.output.dense.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "model.electra.encoder.layer.0.intermediate.dense.weight  (3072, 768)\n",
      "model.electra.encoder.layer.0.intermediate.dense.bias        (3072,)\n",
      "model.electra.encoder.layer.0.output.dense.weight        (768, 3072)\n",
      "model.electra.encoder.layer.0.output.dense.bias               (768,)\n",
      "model.electra.encoder.layer.0.output.LayerNorm.weight         (768,)\n",
      "model.electra.encoder.layer.0.output.LayerNorm.bias           (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "model.classifier.dense.weight                             (768, 768)\n",
      "model.classifier.dense.bias                                   (768,)\n",
      "model.classifier.out_proj.weight                            (3, 768)\n",
      "model.classifier.out_proj.bias                                  (3,)\n"
     ]
    }
   ],
   "source": [
    "if DEBUG==True:\n",
    "    params = list(model.named_parameters())\n",
    "\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c441a1-2ce3-46b2-b52d-c0cce7f76873",
   "metadata": {},
   "source": [
    "## 5. 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4643714-c372-463a-8f7e-2955b2d4376a",
   "metadata": {},
   "source": [
    "### 5-0. Early Stopper 함수 정의\n",
    "\n",
    "- v2에서 코드 일부 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c205350d-ce58-42e7-9558-2b405f142ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        # 첫 에폭\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "           \n",
    "        # loss가 줄지 않는다면 -> patience_counter 1 증가\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            # patience 만큼 loss가 줄지 않았다면 학습을 중단합니다.\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "            print(msg)\n",
    "        # loss가 줄어듬 -> min_loss 갱신, patience_counter 초기화\n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            ### v2 에서 수정됨\n",
    "            ### self.save_model = True -> 삭제 (사용하지 않음)\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d11163-6def-448a-9095-19231e9efe64",
   "metadata": {},
   "source": [
    "### 5-1. Epoch 별 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ed2a1-c2e3-43cb-9967-05d85b8546ee",
   "metadata": {},
   "source": [
    "- [Transformers optimization documentation](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules)\n",
    "- [스케줄러 documentation](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#schedules)\n",
    "- Adam optimizer의 epsilon 파라미터 eps = 1e-8 는 \"계산 중 0으로 나눔을 방지 하기 위한 아주 작은 숫자 \" 입니다. ([출처](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))\n",
    "- 스케줄러 파라미터\n",
    "    - `warmup_ratio` : \n",
    "      - 학습이 진행되면서 학습률을 그 상황에 맞게 가변적으로 적당하게 변경되게 하기 위해 Scheduler를 사용합니다.\n",
    "      - 처음 학습률(Learning rate)를 warm up하기 위한 비율을 설정하는 warmup_ratio을 설정합니다.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2843bac6-6cf1-47bd-8f30-27d99336412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mroywoo\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "2022-03-03 07:45:09.988743: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/roywoo/week3_nlp_roy/runs/36j9cfjh\" target=\"_blank\">celestial-spaceship-46</a></strong> to <a href=\"https://wandb.ai/roywoo/week3_nlp_roy\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/roywoo/week3_nlp_roy/runs/36j9cfjh?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa4095af430>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"week3_nlp_roy\", entity=\"roywoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d151484e-978d-4bf3-b7b3-fe2c5ba5eda5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file loaded.\n",
      "monologg/koelectra-base-v3-hate-speech\n",
      "RUN :  electra_v3_hate_speech_comment_p0\n",
      "batch size :  32\n",
      "The first batch looks like ..\n",
      " {'input_ids': tensor([[[    2, 11139,  6470,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2,  3223,  4114,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2, 15967,   284,  ...,     0,     0,     0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    2,  3080,  4711,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2,  6997,  4880,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2, 12104,  4257,  ...,     0,     0,     0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 236/236 [01:44<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1                 | Train Loss:  0.016                 | Train Accuracy:  0.795                 | Val Loss:  0.010                 | Val Accuracy:  0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 236/236 [01:47<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2                 | Train Loss:  0.009                 | Train Accuracy:  0.887                 | Val Loss:  0.010                 | Val Accuracy:  0.875\n",
      "Validation loss decreased 0.009859162775561515 -> 0.009553241117311066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 236/236 [01:47<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3                 | Train Loss:  0.004                 | Train Accuracy:  0.952                 | Val Loss:  0.017                 | Val Accuracy:  0.766\n",
      "Early stopping counter 1/1\n",
      "Early stopped, Best score :  0.8745519713261649\n",
      "train finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 90851... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>total_acc_train</td><td>▁▅█</td></tr><tr><td>total_acc_val</td><td>██▁</td></tr><tr><td>total_loss_train</td><td>█▄▁</td></tr><tr><td>total_loss_val</td><td>▁▁█</td></tr><tr><td>train_batch_loss</td><td>▄▁█</td></tr><tr><td>val_batch_loss</td><td>▁▁█</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>total_acc_train</td><td>7169</td></tr><tr><td>total_acc_val</td><td>641</td></tr><tr><td>total_loss_train</td><td>33.28057</td></tr><tr><td>total_loss_val</td><td>13.84475</td></tr><tr><td>train_batch_loss</td><td>0.44691</td></tr><tr><td>val_batch_loss</td><td>0.79133</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">celestial-spaceship-46</strong>: <a href=\"https://wandb.ai/roywoo/week3_nlp_roy/runs/36j9cfjh\" target=\"_blank\">https://wandb.ai/roywoo/week3_nlp_roy/runs/36j9cfjh</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220303_074508-36j9cfjh/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = set_config(config_path)\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "# 재현을 위해 모든 곳의 시드 고정\n",
    "seed_val = args.seed\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def train(model, train_data, val_data, args, mode = 'train'):\n",
    "    \n",
    "    # args.run은 실험 이름 (어디까지나 팀원들간의 버전 관리 및 공유 편의를 위한 것으로, 자유롭게 수정 가능합니다.)\n",
    "    print(\"RUN : \", args.run)\n",
    "    shutil.copyfile(\"config.json\", os.path.join(args.config_dir, f\"config_{args.run}.json\"))\n",
    "\n",
    "    early_stopper = LossEarlyStopper(patience=args.patience)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=args.train_batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=args.train_batch_size)\n",
    "\n",
    "    \n",
    "    if DEBUG == True:\n",
    "        # 데이터로더가 성공적으로 로드 되었는지 확인\n",
    "        for idx, data in enumerate(train_dataloader):\n",
    "            if idx==0:\n",
    "                print(\"batch size : \", len(data[0]['input_ids']))\n",
    "                print(\"The first batch looks like ..\\n\", data[0])\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_steps = len(train_dataloader) * args.train_epochs\n",
    "\n",
    "    ### v2에서 수정됨 (Adam -> AdamW)\n",
    "    optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * args.warmup_proportion), \n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.to(DEVICE)\n",
    "        criterion = criterion.to(DEVICE)\n",
    "        \n",
    "\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    best_score = 0.0\n",
    "    best_loss= np.inf\n",
    "      \n",
    "\n",
    "    for epoch_num in range(args.train_epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "            \n",
    "            assert mode in ['train', 'val'], 'your mode should be either \\'train\\' or \\'val\\''\n",
    "            \n",
    "            if mode =='train':\n",
    "                for train_input, train_label in tqdm(train_dataloader):\n",
    "                    \n",
    "                    \n",
    "                    mask = train_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = train_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = train_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    train_label = train_label.long().to(DEVICE)  \n",
    "                    \n",
    "                    ### v2에 수정됨\n",
    "                    optimizer.zero_grad()\n",
    " \n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "                    batch_loss = criterion(output[0].view(-1,3), train_label.view(-1)) #예측해야하는 아웃풋 라벨이 6개에서 3개로 줄어 veiw(-1,6)>view(-1,3)으로 바꿔줌\n",
    "                    total_loss_train += batch_loss.item()\n",
    "\n",
    "                    acc = (output[0].argmax(dim=1) == train_label).sum().item()\n",
    "                    total_acc_train += acc\n",
    "                    \n",
    "                    ### v2에 수정됨\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    ### v2 에 수정됨\n",
    "                    scheduler.step()\n",
    "                    \n",
    "\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            wandb.log({\"train_batch_loss\": batch_loss,\n",
    "                      \"total_loss_train\":total_loss_train,\n",
    "                      \"total_acc_train\": total_acc_train,\n",
    "                      })\n",
    "\n",
    "\n",
    "            \n",
    "            # validation을 위해 이걸 넣으면 이 evaluation 프로세스 중엔 dropout 레이어가 다르가 동작한다.\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    mask = val_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = val_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    val_label = val_label.long().to(DEVICE)\n",
    "\n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "                    ### v2 에서 일부 수정 (output -> output[0]로 myClassifier 모델에 정의된대로 logits 가져옴)\n",
    "                    batch_loss = criterion(output[0].view(-1,3), val_label.view(-1)) #예측해야하는 아웃풋 라벨이 6개에서 3개로 줄어 veiw(-1,6)>view(-1,3)으로 바꿔줌\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    ### v2 에서 일부 수정 (output -> output[0]로 myClassifier 모델에 정의된대로 logits 가져옴)\n",
    "                    acc = (output[0].argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            \n",
    "            train_loss = total_loss_train / len(train_data)\n",
    "            train_accuracy = total_acc_train / len(train_data)\n",
    "            val_loss = total_loss_val / len(val_data)\n",
    "            val_accuracy = total_acc_val / len(val_data)\n",
    "            \n",
    "            wandb.log({\"val_batch_loss\": batch_loss,\n",
    "                      \"total_loss_val\":total_loss_val,\n",
    "                      \"total_acc_val\": total_acc_val,\n",
    "                      })            \n",
    "            # 한 Epoch 학습 후 학습/검증에 대해 loss와 평가지표 (여기서는 accuracy로 임의로 설정) 출력\n",
    "            print(\n",
    "                f'Epoch: {epoch_num + 1} \\\n",
    "                | Train Loss: {train_loss: .3f} \\\n",
    "                | Train Accuracy: {train_accuracy: .3f} \\\n",
    "                | Val Loss: {val_loss: .3f} \\\n",
    "                | Val Accuracy: {val_accuracy: .3f}')\n",
    "          \n",
    "            # early_stopping check\n",
    "            early_stopper.check_early_stopping(loss=val_loss)\n",
    "\n",
    "            if early_stopper.stop:\n",
    "                print('Early stopped, Best score : ', best_score)\n",
    "                break\n",
    "\n",
    "            ### v2 에 수정됨\n",
    "            ### loss와 accuracy가 꼭 correlate하진 않습니다.\n",
    "            ### \n",
    "            ### 원본 (필요하다면 다시 해제 후 사용)\n",
    "            # if val_accuracy > best_score : \n",
    "            if val_loss < best_loss :\n",
    "            # 모델이 개선됨 -> 검증 점수와 베스트 loss, weight 갱신\n",
    "                best_score = val_accuracy \n",
    "                \n",
    "                ### v2에서 추가\n",
    "                best_loss =val_loss\n",
    "                # 학습된 모델을 저장할 디렉토리 및 모델 이름 지정\n",
    "                SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "            \n",
    "                check_point = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict()\n",
    "                }\n",
    "                torch.save(check_point, SAVED_MODEL)  \n",
    "              \n",
    "            # print(\"scheduler : \", scheduler.state_dict())\n",
    "\n",
    "\n",
    "    print(\"train finished\")\n",
    "\n",
    "\n",
    "train(model, train_dataset, val_dataset, args, mode = 'train')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301514c-7d9e-4f37-9e8c-db85e3819b8b",
   "metadata": {},
   "source": [
    "## 6. Test dataset으로 추론 (Prediction)\n",
    "\n",
    "\n",
    "- v2 에서 수정된 부분\n",
    "    - output -> output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32696c34-b5e6-43b3-a1e7-ed8c2847baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 테스트 데이터셋 불러오기\n",
    "test_data = CustomDataset(test_df, tokenizer = TOKENIZER, max_len= args.max_seq_len, mode='test')\n",
    "\n",
    "def test(model, SAVED_MODEL,test_data, args, mode = 'test'):\n",
    "\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=args.eval_batch_size)\n",
    "\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.to(DEVICE)\n",
    "        model.load_state_dict(torch.load(SAVED_MODEL)['model'])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input in test_dataloader:\n",
    "\n",
    "            mask = test_input['attention_mask'].to(DEVICE)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "            segment_ids = test_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "\n",
    "            output = model(input_id, mask, segment_ids)\n",
    "\n",
    "            output = output[0].argmax(dim=1).cpu().tolist()\n",
    "\n",
    "            for label in output:\n",
    "                pred.append(label)\n",
    "                \n",
    "    return pred\n",
    "\n",
    "SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "\n",
    "pred = test(model,SAVED_MODEL, test_data, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "29432647-7a5d-4dda-99af-ad6f151fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction completed for  511 comments\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction completed for \", len(pred), \"comments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aaf8d-93c6-4998-b005-f32ec5986f46",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6bb2e7ea-50e6-4ed6-8840-98460060d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hate_dict = {0: 'none', 1: 'hate', 2: 'hate'} # hate speech 모델은 원래 none offensive hate 3가지로 분류하는 모델이었으나 이자료에서는 offensive와hate가 합쳐졌기 떄문에 둘다 hate로지정\n",
    "pred_hate = ['' for i in range(len(pred))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2551cecd-7477-4746-aa48-74032ad04ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, label in enumerate(pred):\n",
    "    pred_hate[idx]=(str(hate_dict[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4dc13e01-5c14-4e57-b02d-5f84bfb4ee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  bias  hate\n",
       "0      0  none  none\n",
       "1      1  none  none\n",
       "2      2  none  none\n",
       "3      3  none  none\n",
       "4      4  none  none\n",
       "..   ...   ...   ...\n",
       "506  506  none  none\n",
       "507  507  none  none\n",
       "508  508  none  none\n",
       "509  509  none  none\n",
       "510  510  none  none\n",
       "\n",
       "[511 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(os.path.join(args.data_dir,'sample_submission.csv'))\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0ed28510-bc11-42ec-ba20-6c97cc56c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['hate'] = pred_hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8375e664-c360-4cde-92e6-824af2a21b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hate    367\n",
       "none    144\n",
       "Name: hate, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['hate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "70687ff7-e933-4abf-99ad-6866baa4acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(args.result_dir, \"submit_only_hate_normalized.csv\"), index=False) # hate만 지정된 값을 일단 csv파일로만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "48f8bfef-a5da-4b84-8859-16a34b1d4b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_2 = pd.read_csv('./result/submit_only_bias_2.csv') #bias값만 지정해줬던 csv파일 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "579bc77c-e05d-48f4-88d9-3c937e705958",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['bias'] = submit_2['bias']  # hate값만 있는 submit에 bias값만 있는 submit 파일을 합쳐줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24ec61c7-0d2c-4e8c-bbea-e2477bc03b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(args.result_dir, \"submit_last.csv\"), index=False) #파일로저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d973768-21fa-4fe7-99e8-49604f02140f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
